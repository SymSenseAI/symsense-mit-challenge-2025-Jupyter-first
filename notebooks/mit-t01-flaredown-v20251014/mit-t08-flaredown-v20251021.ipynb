{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78cc01db",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/Andria/Desktop/symsense-mit-challenge-2025-Jupyter-first/data/processed/flaredown/feature_matrix_date.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# load data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m feature_matrix = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Users/Andria/Desktop/symsense-mit-challenge-2025-Jupyter-first/data/processed/flaredown/feature_matrix_date.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m symptoms_grouped = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m/Users/Andria/Desktop/symsense-mit-challenge-2025-Jupyter-first/data/processed/flaredown/symptoms_grouped.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m foods_grouped = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m/Users/Andria/Desktop/symsense-mit-challenge-2025-Jupyter-first/data/processed/flaredown/foods_grouped.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.13/lib/python/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.13/lib/python/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.13/lib/python/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.13/lib/python/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.13/lib/python/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/Andria/Desktop/symsense-mit-challenge-2025-Jupyter-first/data/processed/flaredown/feature_matrix_date.csv'"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "feature_matrix = pd.read_csv(\"/Users/Andria/Desktop/symsense-mit-challenge-2025-Jupyter-first/data/processed/flaredown/feature_matrix_date.csv\")\n",
    "\n",
    "symptoms_grouped = pd.read_csv(\"/Users/Andria/Desktop/symsense-mit-challenge-2025-Jupyter-first/data/processed/flaredown/symptoms_grouped.csv\")\n",
    "foods_grouped = pd.read_csv(\"/Users/Andria/Desktop/symsense-mit-challenge-2025-Jupyter-first/data/processed/flaredown/foods_grouped.csv\")\n",
    "tags_grouped = pd.read_csv(\"/Users/Andria/Desktop/symsense-mit-challenge-2025-Jupyter-first/data/processed/flaredown/tags_grouped.csv\")\n",
    "treatments_grouped = pd.read_csv(\"/Users/Andria/Desktop/symsense-mit-challenge-2025-Jupyter-first/data/processed/flaredown/treatments_grouped.csv\")\n",
    "conditions_grouped=pd.read_csv(\"/Users/Andria/Desktop/symsense-mit-challenge-2025-Jupyter-first/data/processed/flaredown/conditions_grouped.csv\")\n",
    "\n",
    "import ast\n",
    "\n",
    "def extract_condition_names(x):\n",
    "    try:\n",
    "        parsed = ast.literal_eval(x)  \n",
    "        if isinstance(parsed, list):\n",
    "            return [item[0].lower().strip() for item in parsed if isinstance(item, (list, tuple))]\n",
    "        elif isinstance(parsed, tuple):\n",
    "            return [parsed[0].lower().strip()]\n",
    "    except Exception:\n",
    "        return []\n",
    "        \n",
    "conditions_grouped['clean_conditions'] = conditions_grouped['conditions_observed'].apply(extract_condition_names)\n",
    "\n",
    "unique_conditions = (\n",
    "    conditions_grouped['clean_conditions']\n",
    "    .explode()\n",
    "    .dropna()\n",
    "    .unique()\n",
    ")\n",
    "print(len(unique_conditions), \"unique clean condition names found\")\n",
    "print(unique_conditions[:50])  \n",
    "\n",
    "import os \n",
    "base_path = \"/Users/Andria/Desktop/symsense-mit-challenge-2025-Jupyter-first/data/processed/flaredown\"\n",
    "pd.Series(unique_conditions).to_csv(\n",
    "    f\"{base_path}/unique_conditions.csv\", \n",
    "    index=False,\n",
    "    header=['condition']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a785284c",
   "metadata": {},
   "source": [
    "## INITIAL MODEL (AUC = 0.644)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated label statistics:\n",
      "Users with autoimmune: 10743\n",
      "Total users: 38308\n",
      "Prevalence: 28.04%\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# COMPREHENSIVE AUTOIMMUNE LIST \n",
    "# ============================================\n",
    "\n",
    "autoimmune_conditions = [\n",
    "    # Endocrine\n",
    "    \"type 1 diabetes\", \"diabetes type 1\", \"graves' disease\", \"graves disease\",\n",
    "    \"hashimoto's thyroiditis\", \"hashimoto's disease\", \"hashimoto\", \"addison's disease\",\n",
    "    \"addison disease\", \"autoimmune thyroiditis\", \"thyroiditis\",\n",
    "    \n",
    "    # Rheumatologic / Connective Tissue\n",
    "    \"rheumatoid arthritis\", \"rheumatoid\", \"systemic lupus erythematosus\", \"lupus\",\n",
    "    \"sle\", \"discoid lupus\", \"cutaneous lupus\", \"scleroderma\", \"systemic sclerosis\",\n",
    "    \"limited scleroderma\", \"crest syndrome\", \"sjogren's syndrome\", \"sjogren\", \"sjögren\",\n",
    "    \"mixed connective tissue disease\", \"mctd\", \"undifferentiated connective tissue disease\",\n",
    "    \"uctd\", \"polymyositis\", \"dermatomyositis\", \"polymyalgia rheumatica\",\n",
    "    \"ankylosing spondylitis\", \"axial spondyloarthritis\", \"psoriatic arthritis\",\n",
    "    \"reactive arthritis\", \"enteropathic arthritis\", \"palindromic rheumatism\",\n",
    "    \"adult still's disease\", \"stills disease\", \"relapsing polychondritis\",\n",
    "    \"behcet's disease\", \"behcet's syndrome\", \"behcets\",\n",
    "    \n",
    "    # Vasculitis\n",
    "    \"vasculitis\", \"granulomatosis with polyangiitis\", \"wegener's granulomatosis\", \"gpa\",\n",
    "    \"microscopic polyangiitis\", \"eosinophilic granulomatosis with polyangiitis\",\n",
    "    \"churg-strauss syndrome\", \"takayasu's arteritis\", \"giant cell arteritis\",\n",
    "    \"temporal arteritis\", \"henoch-schonlein purpura\", \"henoch-schönlein purpura\",\n",
    "    \"iga vasculitis\", \"kawasaki disease\", \"polyarteritis nodosa\",\n",
    "    \n",
    "    # Gastrointestinal\n",
    "    \"crohn's disease\", \"crohn disease\", \"crohns\", \"ulcerative colitis\",\n",
    "    \"inflammatory bowel disease\", \"ibd\", \"celiac disease\", \"celiac\", \"coeliac\",\n",
    "    \"autoimmune hepatitis\", \"primary biliary cholangitis\", \"primary biliary cirrhosis\",\n",
    "    \"pbc\", \"primary sclerosing cholangitis\", \"psc\", \"autoimmune pancreatitis\",\n",
    "    \"autoimmune gastritis\", \"pernicious anemia\", \"autoimmune atrophic gastritis\",\n",
    "    \n",
    "    # Neurological\n",
    "    \"multiple sclerosis\", \"guillain-barre syndrome\", \"guillain barre\",\n",
    "    \"chronic inflammatory demyelinating polyneuropathy\", \"cidp\", \"myasthenia gravis\",\n",
    "    \"lambert-eaton myasthenic syndrome\", \"stiff person syndrome\", \"transverse myelitis\",\n",
    "    \"neuromyelitis optica\", \"autoimmune encephalitis\", \"anti-nmda receptor encephalitis\",\n",
    "    \"hashimoto's encephalopathy\",\n",
    "    \n",
    "    # Hematologic\n",
    "    \"autoimmune hemolytic anemia\", \"immune thrombocytopenic purpura\", \"itp\",\n",
    "    \"immune thrombocytopenia\", \"antiphospholipid syndrome\", \"antiphospholipid antibody syndrome\",\n",
    "    \"aps\", \"aplastic anemia\", \"autoimmune neutropenia\",\n",
    "    \n",
    "    # Dermatologic\n",
    "    \"psoriasis\", \"vitiligo\", \"alopecia areata\", \"pemphigus vulgaris\", \"pemphigus\",\n",
    "    \"bullous pemphigoid\", \"pemphigoid\", \"dermatitis herpetiformis\", \"lichen planus\",\n",
    "    \"lichen sclerosus\", \"morphea\", \"linear scleroderma\",\n",
    "    \n",
    "    # Renal\n",
    "    \"goodpasture syndrome\", \"iga nephropathy\", \"lupus nephritis\", \"anti-gbm disease\",\n",
    "    \n",
    "    # Cardiac\n",
    "    \"autoimmune myocarditis\", \"rheumatic fever\", \"rheumatic heart disease\",\n",
    "    \n",
    "    # Pulmonary\n",
    "    \"sarcoidosis\", \"eosinophilic pneumonia\",\n",
    "    \n",
    "    # Ophthalmologic\n",
    "    \"autoimmune uveitis\", \"graves' ophthalmopathy\", \"thyroid eye disease\",\n",
    "    \n",
    "    # Other/Multi-system\n",
    "    \"igg4-related disease\", \"autoimmune autonomic neuropathy\", \"autoimmune inner ear disease\",\n",
    "    \"raynaud's disease\", \"autoimmune progesterone dermatitis\", \"autoimmune urticaria\",\n",
    "    \"chronic autoimmune urticaria\", \"pans\", \"pandas\",\n",
    "    \n",
    "    # General indicators\n",
    "    \"autoimmune\", \"auto-immune\", \"autoinflammatory\", \"auto-inflammatory\"\n",
    "]\n",
    "\n",
    "# NOT autoimmune \n",
    "not_autoimmune = [\n",
    "    \"ehlers-danlos syndrome\", \"ehlers danlos\", \"eds\", \"hypermobility\",\n",
    "    \"fibromyalgia\", \"chronic fatigue syndrome\", \"myalgic encephalomyelitis\",\n",
    "    \"me/cfs\", \"cfs\", \"mast cell activation syndrome\", \"mcas\",\n",
    "    \"pots\", \"postural orthostatic tachycardia syndrome\", \"dysautonomia\",\n",
    "    \"endometriosis\", \"polycystic ovary syndrome\", \"pcos\",\n",
    "]\n",
    "\n",
    "# ============================================\n",
    "# IMPROVED LABEL CREATION\n",
    "# ============================================\n",
    "\n",
    "def is_autoimmune_condition(condition_text):\n",
    "    \"\"\"Check if a condition is autoimmune\"\"\"\n",
    "    if not condition_text or pd.isna(condition_text):\n",
    "        return False\n",
    "    \n",
    "    condition_lower = str(condition_text).lower().strip()\n",
    "    \n",
    "    # check exclusions\n",
    "    for non_ai in not_autoimmune:\n",
    "        if non_ai in condition_lower:\n",
    "            return False\n",
    "    \n",
    "    # check autoimmune list\n",
    "    for ai_condition in autoimmune_conditions:\n",
    "        if ai_condition in condition_lower:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# apply to conditions_grouped dataframe\n",
    "def extract_condition_names(x):\n",
    "    \"\"\"Extract clean condition names from the conditions_observed column\"\"\"\n",
    "    try:\n",
    "        parsed = ast.literal_eval(x) if isinstance(x, str) else x\n",
    "        if isinstance(parsed, list):\n",
    "            return [item[0].lower().strip() for item in parsed if isinstance(item, (list, tuple))]\n",
    "        elif isinstance(parsed, tuple):\n",
    "            return [parsed[0].lower().strip()]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "conditions_grouped['clean_conditions'] = conditions_grouped['conditions_observed'].apply(extract_condition_names)\n",
    "\n",
    "# create label \n",
    "conditions_grouped['autoimmune_label'] = (\n",
    "    conditions_grouped['clean_conditions']\n",
    "    .apply(lambda x: 1 if any(is_autoimmune_condition(cond) for cond in x) else 0)\n",
    ")\n",
    "\n",
    "# aggregate to user level\n",
    "user_labels = conditions_grouped.groupby('user_id')['autoimmune_label'].max().reset_index()\n",
    "\n",
    "print(f\"\\nUpdated label statistics:\")\n",
    "print(f\"Users with autoimmune: {user_labels['autoimmune_label'].sum()}\")\n",
    "print(f\"Total users: {len(user_labels)}\")\n",
    "print(f\"Prevalence: {user_labels['autoimmune_label'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e865d6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.644\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, classification_report\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv(\"/Users/Andria/Desktop/symsense-mit-challenge-2025-Jupyter-first/data/processed/flaredown/feature_matrix_date.csv\")\n",
    "\n",
    "# encode any object columns (except user_id / checkin_date / target)\n",
    "X = df.drop(\n",
    "    columns=['user_id', 'checkin_date', 'autoimmune_label'] + autoimmune_conditions,\n",
    "    errors='ignore'\n",
    ")\n",
    "y = df['autoimmune_label']\n",
    "\n",
    "groups = df['user_id']\n",
    "\n",
    "# patient-level train/test split\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "# encoding categorial columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_cols)\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_cols)\n",
    "\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# train Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=20, n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate AUC\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "print(f\"AUC: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64949e6",
   "metadata": {},
   "source": [
    "## IMPROVED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e23a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing 3 autoimmune condition columns\n",
      "\n",
      "Feature matrix shape: (359391, 129)\n",
      "Target distribution:\n",
      "autoimmune_label\n",
      "0    333007\n",
      "1     26384\n",
      "Name: count, dtype: int64\n",
      "Positive rate: 7.34%\n",
      "\n",
      "Encoding 4 categorical columns: ['sex', 'country', 'max_symptom_value', 'has_autoimmune']\n",
      "\n",
      "After encoding - Train shape: (250559, 5248), Test shape: (108832, 5248)\n",
      "Scale pos weight: 12.09\n",
      "\n",
      "============================================================\n",
      "TEST 1: WITH has_autoimmune feature (if it exists)\n",
      "============================================================\n",
      "\n",
      "Random Forest AUC (with has_autoimmune): 0.9214\n",
      "XGBoost AUC (with has_autoimmune): 0.9231\n",
      "\n",
      "Top 15 Random Forest features (with has_autoimmune):\n",
      "                feature  importance\n",
      "   has_autoimmune_False    0.159213\n",
      "    has_autoimmune_True    0.148463\n",
      "    num_autoimmune_meds    0.047135\n",
      "  total_symptom_reports    0.028593\n",
      "       total_conditions    0.025610\n",
      "total_treatment_reports    0.022816\n",
      "      total_tag_reports    0.020919\n",
      "num_autoimmune_symptoms    0.020844\n",
      "       takes_prednisone    0.020613\n",
      "    num_unique_symptoms    0.018739\n",
      "num_unique_treatments_y    0.016340\n",
      "     total_food_reports    0.016232\n",
      "          has_stiffness    0.015604\n",
      "      num_unique_tags_y    0.015570\n",
      "       num_unique_foods    0.015529\n",
      "\n",
      "============================================================\n",
      "TEST 2: WITHOUT has_autoimmune feature\n",
      "============================================================\n",
      "\n",
      "Removing 2 has_autoimmune columns: ['has_autoimmune_False', 'has_autoimmune_True']\n",
      "New shape - Train: (250559, 5246), Test: (108832, 5246)\n",
      "\n",
      "Random Forest AUC (without has_autoimmune): 0.7888\n",
      "AUC difference: 0.1326\n",
      "XGBoost AUC (without has_autoimmune): 0.7910\n",
      "AUC difference: 0.1320\n",
      "\n",
      "============================================================\n",
      "Top 20 Random Forest features (WITHOUT has_autoimmune):\n",
      "============================================================\n",
      "                feature  importance\n",
      "    num_autoimmune_meds    0.060250\n",
      "  total_symptom_reports    0.036617\n",
      "       takes_prednisone    0.035107\n",
      "      total_tag_reports    0.033403\n",
      "       total_conditions    0.032198\n",
      "total_treatment_reports    0.031010\n",
      "num_autoimmune_symptoms    0.029616\n",
      "      num_unique_tags_y    0.027958\n",
      "    num_unique_symptoms    0.024463\n",
      "         has_joint_pain    0.023743\n",
      "     total_food_reports    0.022020\n",
      "num_unique_treatments_y    0.021701\n",
      "          has_stiffness    0.021078\n",
      "   avg_symptom_severity    0.020392\n",
      "      num_trigger_foods    0.020304\n",
      "        takes_plaquenil    0.020150\n",
      "       num_unique_foods    0.019782\n",
      "                    age    0.019604\n",
      "   std_symptom_severity    0.017562\n",
      "      avg_foods_per_day    0.015713\n",
      "\n",
      "============================================================\n",
      "Top 20 XGBoost features (WITHOUT has_autoimmune):\n",
      "============================================================\n",
      "                              feature  importance\n",
      "      max_symptom_value_bowel urgency    0.068492\n",
      "                  num_autoimmune_meds    0.060387\n",
      "  max_symptom_value_suicidal thoughts    0.032683\n",
      "  max_symptom_value_speech stuttering    0.029925\n",
      "                       has_joint_pain    0.018870\n",
      "                         has_swelling    0.017458\n",
      "                             eats_egg    0.017311\n",
      "                        has_stiffness    0.015830\n",
      "                             has_rash    0.015236\n",
      "                     takes_prednisone    0.013697\n",
      "                            eats_milk    0.013483\n",
      "                           country_CH    0.012958\n",
      "                     total_conditions    0.011499\n",
      "                           eats_sugar    0.010919\n",
      "                            has_fever    0.010806\n",
      "max_symptom_value_warm hands and feet    0.010588\n",
      "      max_symptom_value_passing blood    0.010406\n",
      "                   total_food_reports    0.010401\n",
      "                           country_US    0.009954\n",
      "              total_treatment_reports    0.009790\n",
      "\n",
      "============================================================\n",
      "SUMMARY: AUC COMPARISON\n",
      "============================================================\n",
      "        Model  With has_autoimmune  Without has_autoimmune  Difference\n",
      "Random Forest             0.921433                0.788839    0.132594\n",
      "      XGBoost             0.923061                0.791016    0.132045\n",
      "\n",
      "============================================================\n",
      "DETAILED METRICS (XGBoost without has_autoimmune)\n",
      "============================================================\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "No Autoimmune       0.96      0.92      0.94    101596\n",
      "   Autoimmune       0.27      0.43      0.33      7236\n",
      "\n",
      "     accuracy                           0.89    108832\n",
      "    macro avg       0.61      0.67      0.63    108832\n",
      " weighted avg       0.91      0.89      0.90    108832\n",
      "\n",
      "\n",
      "============================================================\n",
      "INTERPRETATION GUIDE\n",
      "============================================================\n",
      "GOOD: 0.75 ≤ AUC < 0.85\n",
      "   Model is useful for clinical screening.\n",
      "   Better than original 0.644 AUC!\n",
      "Moderate AUC drop (0.1320): has_autoimmune helped but model is still strong\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ============================================\n",
    "# LOAD ENRICHED FEATURE MATRIX\n",
    "# ============================================\n",
    "\n",
    "# use enriched feature matrix \n",
    "df = pd.read_csv(\"/Users/Andria/Desktop/symsense-mit-challenge-2025-Jupyter-first/data/processed/flaredown/feature_matrix_enriched.csv\")\n",
    "\n",
    "# ============================================\n",
    "# PREPARE DATA\n",
    "# ============================================\n",
    "\n",
    "# check which columns to drop\n",
    "cols_to_drop = ['user_id', 'checkin_date', 'autoimmune_label']\n",
    "\n",
    "# remove autoimmune condition columns \n",
    "autoimmune_condition_cols = [col for col in df.columns if col in autoimmune_conditions]\n",
    "print(f\"\\nRemoving {len(autoimmune_condition_cols)} autoimmune condition columns\")\n",
    "\n",
    "X = df.drop(columns=cols_to_drop + autoimmune_condition_cols, errors='ignore')\n",
    "y = df['autoimmune_label']\n",
    "groups = df['user_id']\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "print(f\"Positive rate: {y.mean():.2%}\")\n",
    "\n",
    "# ============================================\n",
    "# PATIENT-LEVEL TRAIN/TEST SPLIT\n",
    "# ============================================\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "# encode categorical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "if categorical_cols:\n",
    "    print(f\"\\nEncoding {len(categorical_cols)} categorical columns: {categorical_cols}\")\n",
    "    X_train = pd.get_dummies(X_train, columns=categorical_cols)\n",
    "    X_test = pd.get_dummies(X_test, columns=categorical_cols)\n",
    "    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "print(f\"\\nAfter encoding - Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "# class imbalance\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Scale pos weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# ============================================\n",
    "# TEST 1: WITH has_autoimmune FEATURE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST 1: WITH has_autoimmune feature\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# train Random Forest\n",
    "rf_model_with = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    max_depth=20, \n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1, \n",
    "    random_state=42\n",
    ")\n",
    "rf_model_with.fit(X_train, y_train)\n",
    "\n",
    "y_pred_prob_rf_with = rf_model_with.predict_proba(X_test)[:, 1]\n",
    "auc_rf_with = roc_auc_score(y_test, y_pred_prob_rf_with)\n",
    "\n",
    "print(f\"\\nRandom Forest AUC (with has_autoimmune): {auc_rf_with:.4f}\")\n",
    "\n",
    "# train XGBoost\n",
    "xgb_model_with = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='auc'\n",
    ")\n",
    "xgb_model_with.fit(X_train, y_train)\n",
    "\n",
    "y_pred_prob_xgb_with = xgb_model_with.predict_proba(X_test)[:, 1]\n",
    "auc_xgb_with = roc_auc_score(y_test, y_pred_prob_xgb_with)\n",
    "\n",
    "print(f\"XGBoost AUC (with has_autoimmune): {auc_xgb_with:.4f}\")\n",
    "\n",
    "# feature importance for Random Forest\n",
    "rf_importance_with = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model_with.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Random Forest features (with has_autoimmune):\")\n",
    "print(rf_importance_with.head(15).to_string(index=False))\n",
    "\n",
    "# ============================================\n",
    "# TEST 2: WITHOUT has_autoimmune FEATURE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST 2: WITHOUT has_autoimmune feature\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# remove has_autoimmune related columns\n",
    "has_autoimmune_cols = [col for col in X_train.columns if 'has_autoimmune' in col.lower()]\n",
    "print(f\"\\nRemoving {len(has_autoimmune_cols)} has_autoimmune columns: {has_autoimmune_cols}\")\n",
    "\n",
    "X_train_no_ai = X_train.drop(columns=has_autoimmune_cols, errors='ignore')\n",
    "X_test_no_ai = X_test.drop(columns=has_autoimmune_cols, errors='ignore')\n",
    "\n",
    "print(f\"New shape - Train: {X_train_no_ai.shape}, Test: {X_test_no_ai.shape}\")\n",
    "\n",
    "# train Random Forest without has_autoimmune\n",
    "rf_model_without = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    max_depth=20, \n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1, \n",
    "    random_state=42\n",
    ")\n",
    "rf_model_without.fit(X_train_no_ai, y_train)\n",
    "\n",
    "y_pred_prob_rf_without = rf_model_without.predict_proba(X_test_no_ai)[:, 1]\n",
    "auc_rf_without = roc_auc_score(y_test, y_pred_prob_rf_without)\n",
    "\n",
    "print(f\"\\nRandom Forest AUC (without has_autoimmune): {auc_rf_without:.4f}\")\n",
    "print(f\"AUC difference: {auc_rf_with - auc_rf_without:.4f}\")\n",
    "\n",
    "# train XGBoost without has_autoimmune\n",
    "xgb_model_without = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='auc'\n",
    ")\n",
    "xgb_model_without.fit(X_train_no_ai, y_train)\n",
    "\n",
    "y_pred_prob_xgb_without = xgb_model_without.predict_proba(X_test_no_ai)[:, 1]\n",
    "auc_xgb_without = roc_auc_score(y_test, y_pred_prob_xgb_without)\n",
    "\n",
    "print(f\"XGBoost AUC (without has_autoimmune): {auc_xgb_without:.4f}\")\n",
    "print(f\"AUC difference: {auc_xgb_with - auc_xgb_without:.4f}\")\n",
    "\n",
    "# feature importance without has_autoimmune\n",
    "rf_importance_without = pd.DataFrame({\n",
    "    'feature': X_train_no_ai.columns,\n",
    "    'importance': rf_model_without.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "xgb_importance_without = pd.DataFrame({\n",
    "    'feature': X_train_no_ai.columns,\n",
    "    'importance': xgb_model_without.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Top 20 Random Forest features (WITHOUT has_autoimmune):\")\n",
    "print(\"=\"*60)\n",
    "print(rf_importance_without.head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Top 20 XGBoost features (WITHOUT has_autoimmune):\")\n",
    "print(\"=\"*60)\n",
    "print(xgb_importance_without.head(20).to_string(index=False))\n",
    "\n",
    "# ============================================\n",
    "# COMPARISON SUMMARY\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY: AUC COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_summary = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'XGBoost'],\n",
    "    'With has_autoimmune': [auc_rf_with, auc_xgb_with],\n",
    "    'Without has_autoimmune': [auc_rf_without, auc_xgb_without],\n",
    "    'Difference': [auc_rf_with - auc_rf_without, auc_xgb_with - auc_xgb_without]\n",
    "})\n",
    "\n",
    "print(results_summary.to_string(index=False))\n",
    "\n",
    "# ============================================\n",
    "# DETAILED METRICS FOR BEST MODEL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED METRICS (XGBoost without has_autoimmune)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_pred_class = (y_pred_prob_xgb_without > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred_class, target_names=['No Autoimmune', 'Autoimmune']))\n",
    "\n",
    "# ============================================\n",
    "# INTERPRETATION GUIDE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTERPRETATION GUIDE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if auc_xgb_without >= 0.85:\n",
    "    print(\"EXCELLENT: AUC ≥ 0.85\")\n",
    "    print(\"   Model is strong even without condition features\")\n",
    "    print(\"   Can predict autoimmune from symptoms/medications alone.\")\n",
    "    \n",
    "elif auc_xgb_without >= 0.75:\n",
    "    print(\"GOOD: 0.75 ≤ AUC < 0.85\")\n",
    "    print(\"   Model is useful for clinical screening.\")\n",
    "    print(\"   Better than original 0.644 AUC!\")\n",
    "    \n",
    "elif auc_xgb_without >= 0.65:\n",
    "    print(\"FAIR: 0.65 ≤ AUC < 0.75\")\n",
    "    print(\"   Model has predictive value but needs improvement.\")\n",
    "    \n",
    "else:\n",
    "    print(\"POOR: AUC < 0.65\")\n",
    "    print(\"   has_autoimmune carrying most of the weight.\")\n",
    "    print(\"   Need significant feature engineering improvements.\")\n",
    "\n",
    "auc_drop = auc_xgb_with - auc_xgb_without\n",
    "if auc_drop < 0.05:\n",
    "    print(f\"Small AUC drop ({auc_drop:.4f}): has_autoimmune wasn't critical\")\n",
    "elif auc_drop < 0.15:\n",
    "    print(f\"Moderate AUC drop ({auc_drop:.4f}): has_autoimmune helped but model is still strong\")\n",
    "else:\n",
    "    print(f\"Large AUC drop ({auc_drop:.4f}): has_autoimmune was very important\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74ea17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 21 leakage columns:\n",
      "avg_condition_value\n",
      "has_autoimmune\n",
      "lupus\n",
      "max_condition_value\n",
      "num_autoimmune_meds\n",
      "num_autoimmune_symptoms\n",
      "num_conditions\n",
      "rheumatoid arthritis\n",
      "takes_azathioprine\n",
      "takes_enbrel\n",
      "takes_humira\n",
      "takes_hydroxychloroquine\n",
      "takes_methotrexate\n",
      "takes_methylprednisolone\n",
      "takes_plaquenil\n",
      "takes_prednisolone\n",
      "takes_prednisone\n",
      "takes_remicade\n",
      "takes_rituximab\n",
      "total_conditions\n",
      "ulcerative colitis\n",
      "\n",
      "Clean data shape: (359391, 114)\n",
      "Found 38 symptom columns\n",
      "Created 30 new features\n",
      "Encoding 3 categorical columns: ['sex', 'country', 'max_symptom_value']\n",
      "Feature matrix: (359391, 6575)\n",
      "Train: 250559, Test: 108832\n",
      "Train positive rate: 7.64%, Test positive rate: 6.65%\n",
      "\n",
      "Training XGBoost...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"/Users/Andria/Desktop/symsense-mit-challenge-2025-Jupyter-first/data/processed/flaredown/feature_matrix_enriched.csv\")\n",
    "\n",
    "# removing leakage features\n",
    "leakage_patterns = [\n",
    "    'autoimmune', 'lupus', 'rheumatoid', 'psoriasis', 'crohn', \n",
    "    'celiac', 'hashimoto', 'graves', 'sjogren', 'ulcerative',\n",
    "    'plaquenil', 'hydroxychloroquine', 'methotrexate', 'humira',\n",
    "    'enbrel', 'remicade', 'rituximab', 'azathioprine',\n",
    "    'num_conditions', 'total_conditions', 'avg_condition_value', 'max_condition_value',\n",
    "    'prednisone', 'prednisolone'\n",
    "]\n",
    "\n",
    "leakage_cols = []\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    for pattern in leakage_patterns:\n",
    "        if pattern in col_lower and col != 'autoimmune_label':\n",
    "            leakage_cols.append(col)\n",
    "            break\n",
    "\n",
    "leakage_cols = list(set(leakage_cols))\n",
    "print(f\"Removing {len(leakage_cols)} leakage columns:\")\n",
    "for col in sorted(leakage_cols):\n",
    "    print(f\"{col}\")\n",
    "\n",
    "clean_df = df.drop(columns=leakage_cols, errors='ignore')\n",
    "print(f\"\\nClean data shape: {clean_df.shape}\")\n",
    "\n",
    "# using legitimate features\n",
    "enhanced = clean_df.copy()\n",
    "new_features = []\n",
    "\n",
    "# identify symptom columns\n",
    "has_cols = [c for c in clean_df.columns if c.startswith('has_')]\n",
    "print(f\"Found {len(has_cols)} symptom columns\")\n",
    "\n",
    "# convert to boolean by checking > 0\n",
    "def has_symptom(col):\n",
    "    \"\"\"Convert float column to boolean (> 0 means has symptom)\"\"\"\n",
    "    return (clean_df[col] > 0).astype(int)\n",
    "\n",
    "# symptom combinations\n",
    "if 'has_joint_pain' in clean_df.columns and 'has_stiffness' in clean_df.columns:\n",
    "    enhanced['joint_stiffness_combo'] = ((clean_df['has_joint_pain'] > 0) & (clean_df['has_stiffness'] > 0)).astype(int)\n",
    "    new_features.append('joint_stiffness_combo')\n",
    "\n",
    "if 'has_joint_pain' in clean_df.columns and 'has_fatigue' in clean_df.columns:\n",
    "    enhanced['joint_fatigue_combo'] = ((clean_df['has_joint_pain'] > 0) & (clean_df['has_fatigue'] > 0)).astype(int)\n",
    "    new_features.append('joint_fatigue_combo')\n",
    "\n",
    "if 'has_stiffness' in clean_df.columns and 'has_fatigue' in clean_df.columns:\n",
    "    enhanced['stiffness_fatigue_combo'] = ((clean_df['has_stiffness'] > 0) & (clean_df['has_fatigue'] > 0)).astype(int)\n",
    "    new_features.append('stiffness_fatigue_combo')\n",
    "\n",
    "if 'has_rash' in clean_df.columns and 'has_fatigue' in clean_df.columns:\n",
    "    enhanced['rash_fatigue_combo'] = ((clean_df['has_rash'] > 0) & (clean_df['has_fatigue'] > 0)).astype(int)\n",
    "    new_features.append('rash_fatigue_combo')\n",
    "\n",
    "if 'has_joint_pain' in clean_df.columns and 'has_swelling' in clean_df.columns:\n",
    "    enhanced['joint_swelling_combo'] = ((clean_df['has_joint_pain'] > 0) & (clean_df['has_swelling'] > 0)).astype(int)\n",
    "    new_features.append('joint_swelling_combo')\n",
    "\n",
    "if 'has_fever' in clean_df.columns and 'has_fatigue' in clean_df.columns:\n",
    "    enhanced['fever_fatigue_combo'] = ((clean_df['has_fever'] > 0) & (clean_df['has_fatigue'] > 0)).astype(int)\n",
    "    new_features.append('fever_fatigue_combo')\n",
    "\n",
    "# triple combinations\n",
    "if all(c in clean_df.columns for c in ['has_joint_pain', 'has_stiffness', 'has_fatigue']):\n",
    "    enhanced['classic_autoimmune_triad'] = (\n",
    "        (clean_df['has_joint_pain'] > 0) & (clean_df['has_stiffness'] > 0) & (clean_df['has_fatigue'] > 0)\n",
    "    ).astype(int)\n",
    "    new_features.append('classic_autoimmune_triad')\n",
    "\n",
    "if all(c in clean_df.columns for c in ['has_rash', 'has_joint_pain', 'has_fatigue']):\n",
    "    enhanced['lupus_like_pattern'] = (\n",
    "        (clean_df['has_rash'] > 0) & (clean_df['has_joint_pain'] > 0) & (clean_df['has_fatigue'] > 0)\n",
    "    ).astype(int)\n",
    "    new_features.append('lupus_like_pattern')\n",
    "\n",
    "# multi-system involvement (how many symptom types > 0)\n",
    "if len(has_cols) >= 3:\n",
    "    enhanced['total_symptom_types'] = (clean_df[has_cols] > 0).sum(axis=1)\n",
    "    enhanced['has_3plus_symptoms'] = (enhanced['total_symptom_types'] >= 3).astype(int)\n",
    "    enhanced['has_4plus_symptoms'] = (enhanced['total_symptom_types'] >= 4).astype(int)\n",
    "    enhanced['has_5plus_symptoms'] = (enhanced['total_symptom_types'] >= 5).astype(int)\n",
    "    new_features.extend(['total_symptom_types', 'has_3plus_symptoms', 'has_4plus_symptoms', 'has_5plus_symptoms'])\n",
    "\n",
    "# age features\n",
    "if 'age' in clean_df.columns:\n",
    "    enhanced['age_20_30'] = ((clean_df['age'] >= 20) & (clean_df['age'] < 30)).astype(int)\n",
    "    enhanced['age_30_40'] = ((clean_df['age'] >= 30) & (clean_df['age'] < 40)).astype(int)\n",
    "    enhanced['age_40_50'] = ((clean_df['age'] >= 40) & (clean_df['age'] < 50)).astype(int)\n",
    "    enhanced['age_squared'] = clean_df['age'] ** 2\n",
    "    new_features.extend(['age_20_30', 'age_30_40', 'age_40_50', 'age_squared'])\n",
    "\n",
    "# sex interactions\n",
    "if 'sex' in clean_df.columns:\n",
    "    if clean_df['sex'].dtype == 'object':\n",
    "        is_female = clean_df['sex'].str.lower().isin(['female', 'f'])\n",
    "    else:\n",
    "        is_female = clean_df['sex'] == 1\n",
    "    \n",
    "    enhanced['is_female'] = is_female.astype(int)\n",
    "    new_features.append('is_female')\n",
    "    \n",
    "    if 'age' in clean_df.columns:\n",
    "        enhanced['female_age_20_45'] = (is_female & (clean_df['age'] >= 20) & (clean_df['age'] <= 45)).astype(int)\n",
    "        enhanced['female_age_product'] = is_female.astype(int) * clean_df['age']\n",
    "        new_features.extend(['female_age_20_45', 'female_age_product'])\n",
    "    \n",
    "    if 'has_joint_pain' in clean_df.columns:\n",
    "        enhanced['female_joint_pain'] = (is_female & (clean_df['has_joint_pain'] > 0)).astype(int)\n",
    "        new_features.append('female_joint_pain')\n",
    "    \n",
    "    if 'has_fatigue' in clean_df.columns:\n",
    "        enhanced['female_fatigue'] = (is_female & (clean_df['has_fatigue'] > 0)).astype(int)\n",
    "        new_features.append('female_fatigue')\n",
    "\n",
    "# severity patterns\n",
    "if 'avg_symptom_severity' in clean_df.columns:\n",
    "    enhanced['high_avg_severity'] = (clean_df['avg_symptom_severity'] > clean_df['avg_symptom_severity'].median()).astype(int)\n",
    "    enhanced['very_high_severity'] = (clean_df['avg_symptom_severity'] > clean_df['avg_symptom_severity'].quantile(0.75)).astype(int)\n",
    "    new_features.extend(['high_avg_severity', 'very_high_severity'])\n",
    "\n",
    "if 'std_symptom_severity' in clean_df.columns:\n",
    "    enhanced['variable_symptoms'] = (clean_df['std_symptom_severity'] > clean_df['std_symptom_severity'].median()).astype(int)\n",
    "    new_features.append('variable_symptoms')\n",
    "\n",
    "# engagement patterns\n",
    "if 'total_symptom_reports' in clean_df.columns:\n",
    "    enhanced['high_symptom_reporting'] = (clean_df['total_symptom_reports'] > clean_df['total_symptom_reports'].median()).astype(int)\n",
    "    new_features.append('high_symptom_reporting')\n",
    "\n",
    "if 'num_unique_symptoms' in clean_df.columns:\n",
    "    enhanced['many_unique_symptoms'] = (clean_df['num_unique_symptoms'] > clean_df['num_unique_symptoms'].median()).astype(int)\n",
    "    new_features.append('many_unique_symptoms')\n",
    "\n",
    "# food triggers\n",
    "if 'num_trigger_foods' in clean_df.columns:\n",
    "    enhanced['has_food_triggers'] = (clean_df['num_trigger_foods'] > 0).astype(int)\n",
    "    enhanced['multiple_food_triggers'] = (clean_df['num_trigger_foods'] >= 3).astype(int)\n",
    "    new_features.extend(['has_food_triggers', 'multiple_food_triggers'])\n",
    "\n",
    "# complex interactions\n",
    "if 'avg_symptom_severity' in clean_df.columns and 'total_symptom_types' in enhanced.columns:\n",
    "    enhanced['severity_count_interaction'] = clean_df['avg_symptom_severity'] * enhanced['total_symptom_types']\n",
    "    new_features.append('severity_count_interaction')\n",
    "\n",
    "if 'age' in clean_df.columns and 'total_symptom_types' in enhanced.columns:\n",
    "    enhanced['age_symptom_count'] = clean_df['age'] * enhanced['total_symptom_types']\n",
    "    new_features.append('age_symptom_count')\n",
    "\n",
    "print(f\"Created {len(new_features)} new features\")\n",
    "\n",
    "# model training\n",
    "cols_to_drop = ['autoimmune_label', 'user_id', 'checkin_date']\n",
    "X = enhanced.drop(columns=[c for c in cols_to_drop if c in enhanced.columns])\n",
    "y = enhanced['autoimmune_label']\n",
    "groups = enhanced['user_id']\n",
    "\n",
    "# encode categorical\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "if cat_cols:\n",
    "    print(f\"Encoding {len(cat_cols)} categorical columns: {cat_cols}\")\n",
    "    X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "\n",
    "print(f\"Feature matrix: {X.shape}\")\n",
    "\n",
    "# patient-level split\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "print(f\"Train positive rate: {y_train.mean():.2%}, Test positive rate: {y_test.mean():.2%}\")\n",
    "\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "# train XGBoost\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='auc',\n",
    "    verbosity=0\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict_proba(X_test)[:, 1]\n",
    "xgb_auc = roc_auc_score(y_test, xgb_pred)\n",
    "\n",
    "# train Random Forest\n",
    "print(\"Training Random Forest...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    min_samples_split=10,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict_proba(X_test)[:, 1]\n",
    "rf_auc = roc_auc_score(y_test, rf_pred)\n",
    "\n",
    "# result printing\n",
    "print(f\"\\nXGBoost AUC: {xgb_auc:.4f}\")\n",
    "print(f\"Random Forest AUC: {rf_auc:.4f}\")\n",
    "\n",
    "best_auc = max(xgb_auc, rf_auc)\n",
    "best_name = \"XGBoost\" if xgb_auc > rf_auc else \"Random Forest\"\n",
    "best_model = xgb_model if xgb_auc > rf_auc else rf_model\n",
    "best_pred = xgb_pred if xgb_auc > rf_auc else rf_pred\n",
    "\n",
    "print(f\"BEST MODEL: {best_name} with AUC {best_auc:.4f}\")\n",
    "\n",
    "# Comparison\n",
    "print(\"COMPARISON\")\n",
    "print(f\"Previous AUC WITH leakage: 0.7910\")\n",
    "print(f\"Current AUC WITHOUT leakage: {best_auc:.4f}\")\n",
    "print(f\"Difference: {0.7910 - best_auc:.4f}\")\n",
    "\n",
    "# feature importance\n",
    "importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"TOP 25 FEATURES\")\n",
    "print(importance.head(25).to_string(index=False))\n",
    "\n",
    "# classification report\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "y_pred_class = (best_pred > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred_class, target_names=['No Autoimmune', 'Autoimmune']))\n",
    "\n",
    "# check for remaining leakage\n",
    "print(\"LEAKAGE CHECK\")\n",
    "top_10 = importance.head(10)['feature'].tolist()\n",
    "suspicious = ['autoimmune', 'condition', 'prednisone', 'plaquenil', 'methotrexate']\n",
    "found_suspicious = [f for f in top_10 if any(s in f.lower() for s in suspicious)]\n",
    "\n",
    "if found_suspicious:\n",
    "    print(\"Possible remaining leakage:\")\n",
    "    for f in found_suspicious:\n",
    "        print(f\"   - {f}\")\n",
    "else:\n",
    "    print(\"No obvious leakage in top features\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
